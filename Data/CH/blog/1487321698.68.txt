回答关于网页重排的问题人民搜索的同事问我此前写的网页重排的博客，其实用【网页重排 pennyliang】就可以搜索到，http://blog.csdn.net/pennyliang/archive/2010/08/02/5781847.aspx。


    在WWW2010大会上，有一篇论文写的很好，总结了这方面的方法，也提出了新的方法：


    Scalable Techniques for Document Identifier Assignment in Inverted Indexes


    


    这个问题基本是这样的：


    在做索引的过程中，文档号的分配和最终倒排表制作出来的大小和query的效率有非常大的影响。本质上来说，这是由于关键词的高维空间决定的，我们可以想象每个关键词是一个维，那么如果有30万词汇的话，就是一个30万维的空间，每个文档做出的一个正排表，可以想象成这个高维空间的一个点。变成倒排表后，如果文档数是10B（100亿），可以看做是一个关键词在这个10B高维空间的一个点，而要想让每个维上的投影都是致密的是不现实的，不难得到，最多只有3个关键词可以做到doclist上的docid完全连续，即全部gap=1。


    


    解决的办法基本有这样一些：


    （1）做聚类，分类，用类别的信息，让同一类的doc连续分配docid。


    （2）简单的按URL排序，因为URL近似的网页内容也大多相似，这样可以节省分类聚类的开销


    （3）直接用网页抓取的顺序，也就是近似random的顺序。


    


    WWW2010的这篇论文提出了新的方法，实验效果也更佳，可以借鉴参考，我原来以为这个坑挖到头了，没想到还能有突破。


   


    如果无法下载这篇论文，可以给我留个邮箱。